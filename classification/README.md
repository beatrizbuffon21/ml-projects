# ğŸ¦ AnÃ¡lise e PrediÃ§Ã£o de AprovaÃ§Ã£o de EmprÃ©stimos

Projeto de **Machine Learning aplicado Ã  concessÃ£o de crÃ©dito**, com foco em identificar os fatores que influenciam a aprovaÃ§Ã£o de emprÃ©stimos e comparar diferentes modelos de classificaÃ§Ã£o.

---

## ğŸ“Š 1. VisÃ£o Geral do Projeto

O objetivo Ã© **prever a aprovaÃ§Ã£o (`Loan_Approved`)** com base em informaÃ§Ãµes financeiras e demogrÃ¡ficas dos solicitantes, como renda, score de crÃ©dito, valor do emprÃ©stimo e endividamento.

**Etapas principais:**
1. AnÃ¡lise estatÃ­stica descritiva e exploraÃ§Ã£o dos dados  
2. PrÃ©-processamento e codificaÃ§Ã£o de variÃ¡veis  
3. Treinamento e avaliaÃ§Ã£o de modelos supervisionados  
4. InterpretaÃ§Ã£o e comparaÃ§Ã£o de desempenho  
5. AnÃ¡lise de importÃ¢ncia das variÃ¡veis e curva de aprendizado  

---

## ğŸ“ˆ 2. Resumo EstatÃ­stico

| VariÃ¡vel | InterpretaÃ§Ã£o EstatÃ­stica | Insight AnalÃ­tico |
|-----------|---------------------------|-------------------|
| **Applicant_Income** | MÃ©dia â‰ˆ 10.8k, desvio â‰ˆ 4.9k | Renda do titular com alta dispersÃ£o e forte assimetria positiva. |
| **Coapplicant_Income** | MÃ©dia â‰ˆ 5.0k | Co-solicitante (geralmente cÃ´njuge) complementa a renda familiar. |
| **Credit_Score** | MÃ©dia â‰ˆ 676 | Score mÃ©dio-alto, fator chave na aprovaÃ§Ã£o. |
| **DTI_Ratio** | MÃ©dia â‰ˆ 0.35 (35%) | Endividamento moderado; valores > 0.5 indicam maior risco. |
| **Loan_Amount** | MÃ©dia â‰ˆ 20.5k | Aprovados tendem a solicitar valores prÃ³ximos Ã  mediana (~R$18â€“20k). |
| **Collateral_Value** | MÃ©dia â‰ˆ 24.7k | Valor variÃ¡vel; nÃ£o Ã© determinante isolado na aprovaÃ§Ã£o. |

---

## âš–ï¸ 3. DistribuiÃ§Ãµes e Perfil da Base

- **Loan_Approved** â†’ 26% aprovados, 74% rejeitados âœ base **desbalanceada**.  
- **GÃªnero** â†’ 62% homens, 38% mulheres.  
- **Estado civil** â†’ 64% casados.  
- **Idade mÃ©dia** â†’ 40 anos (intervalo 21â€“59).  

ğŸ’¡ *PÃºblico predominantemente adulto, casado e de renda mÃ©dia, refletindo perfil de estabilidade financeira.*

---

## ğŸ” 4. CorrelaÃ§Ãµes com AprovaÃ§Ã£o

| VariÃ¡vel | CorrelaÃ§Ã£o | InterpretaÃ§Ã£o |
|-----------|-------------|---------------|
| **Credit_Score** | +0.45 | Quanto maior o score, maior a chance de aprovaÃ§Ã£o. |
| **DTI_Ratio** | -0.44 | Endividamento alto reduz probabilidade de aprovaÃ§Ã£o. |
| **Applicant_Income** | +0.12 | Renda ajuda, mas nÃ£o Ã© fator decisivo isoladamente. |
| **Loan_Amount** | -0.13 | Valores altos tendem a ser mais rejeitados. |

âœ… Nenhuma variÃ¡vel apresenta multicolinearidade (VIF < 2).

---

## âš™ï¸ 5. PrÃ©-processamento

- **LabelEncoder** â†’ variÃ¡veis binÃ¡rias/ordinais (ex.: `Gender`, `Marital_Status`).  
- **One-Hot Encoding** â†’ variÃ¡veis nominais (ex.: `Loan_Purpose`, `Employer_Category`).  
- **PadronizaÃ§Ã£o (StandardScaler)** â†’ centraliza e escala variÃ¡veis numÃ©ricas.  
- **DivisÃ£o dos dados:** 60% treino / 40% teste (`random_state=42`).  

---

## ğŸ¤– 6. Modelagem Preditiva

Modelos treinados:
- **RegressÃ£o LogÃ­stica**
- **SVM (kernel RBF)**
- **Random Forest (200 Ã¡rvores)**

Cada modelo foi avaliado em termos de acurÃ¡cia, precisÃ£o, recall, F1-score, AUC e calibraÃ§Ã£o.

---

## ğŸ“Š 7. Desempenho dos Modelos

| Modelo | AcurÃ¡cia | PrecisÃ£o | Recall | F1 | ObservaÃ§Ãµes |
|--------|-----------|-----------|--------|----|-------------|
| **RegressÃ£o LogÃ­stica** | 0.84 | 0.81 | 0.66 | 0.73 | Boa explicabilidade, leve perda de recall. |
| **SVM (RBF)** | 0.83 | 0.85 | 0.58 | 0.69 | Conservador, evita falsos positivos. |
| **Random Forest** | ğŸ¥‡ 0.90 | 0.88 | 0.80 | 0.84 | Melhor equilÃ­brio geral, robusto e nÃ£o linear. |

---

## ğŸ“ˆ 8. AvaliaÃ§Ã£o Detalhada

| MÃ©trica | RegressÃ£o LogÃ­stica | SVM | Random Forest |
|----------|----------------------|-----|----------------|
| **AUC (ROC)** | 0.91 | 0.93 | ğŸ¥‡ 0.96 |
| **F1-score** | 0.78 | 0.80 | ğŸ¥‡ 0.91 |
| **PrecisÃ£o (1)** | 0.76 | 0.73 | ğŸ¥‡ 0.85 |
| **Recall (1)** | 0.80 | 0.89 | ğŸ¥‡ 0.98 |
| **Brier Score** | 0.115 | 0.105 | ğŸ¥‡ 0.082 |

ğŸ”¹ **Random Forest** â†’ melhor performance global  
ğŸ”¹ **RegressÃ£o LogÃ­stica** â†’ melhor calibraÃ§Ã£o  
ğŸ”¹ **SVM** â†’ bom recall, mas menos interpretÃ¡vel

---

## ğŸŒ¡ï¸ 9. CalibraÃ§Ã£o e Curva ROC

- **RegressÃ£o LogÃ­stica**: calibraÃ§Ã£o quase perfeita, AUC = 0.91  
- **SVM**: AUC = 0.93, AP = 0.85, leve subestimaÃ§Ã£o em extremos  
- **Random Forest**: AUC = 0.96, bem calibrado apÃ³s threshold Ã³timo (0.32)

---

## ğŸŒ³ 10. ImportÃ¢ncia das VariÃ¡veis (Random Forest)

| VariÃ¡vel mais relevante | Impacto |
|--------------------------|---------|
| **Credit_Score** | Mais importante na decisÃ£o de aprovaÃ§Ã£o |
| **DTI_Ratio** | Endividamento elevado reduz probabilidade |
| **Applicant_Income** | Renda ajuda, mas depende do score |
| **Loan_Amount** | EmprÃ©stimos muito altos tendem Ã  rejeiÃ§Ã£o |

ğŸ“Š O modelo combina mÃºltiplas dimensÃµes de risco, sem depender apenas da renda.

---

## ğŸ“š 11. Curva de Aprendizado

- AUC de **validaÃ§Ã£o estabiliza em 0.97â€“0.98** apÃ³s ~200 observaÃ§Ãµes.  
- Gap mÃ­nimo entre treino e validaÃ§Ã£o â†’ **excelente generalizaÃ§Ã£o**.  
- Pouco risco de overfitting.

---

## ğŸ§© 12. ConclusÃ£o Geral

| Objetivo | Modelo Ideal | Motivo |
|-----------|---------------|--------|
| **Alta performance preditiva** | ğŸ¥‡ **Random Forest** | Melhor AUC, F1 e Recall |
| **Explicabilidade e anÃ¡lise de risco** | **RegressÃ£o LogÃ­stica** | CalibraÃ§Ã£o e interpretabilidade |
| **Triagem ampla (sensÃ­vel)** | **SVM** | Recall elevado, cauteloso na aprovaÃ§Ã£o |

ğŸ”¹ **Melhor modelo final:** `Random Forest`  
ğŸ”¹ **AUC = 0.96**, **F1 = 0.91**, **generalizaÃ§Ã£o excelente**  

---

## ğŸ§  13. PrÃ³ximos Passos

- Aplicar **SMOTE** ou `class_weight='balanced'` para lidar com o desbalanceamento.  
- Testar **XGBoost ou LightGBM** para comparaÃ§Ã£o.  
- Implementar **explicabilidade local (SHAP values)**.  
- Deploy em API (Flask/FastAPI) para uso real.

---

## ğŸ§¾ Autor
**Gepeto**  
ğŸ“ UFSM â€” Departamento de EstatÃ­stica  
ğŸ“§ Contato acadÃªmico / profissional  
ğŸ”— [LinkedIn / GitHub / Lattes â€“ opcional]

---

## ğŸ§  Tecnologias Principais
- Python 3.13  
- pandas, numpy, matplotlib, seaborn  
- scikit-learn, statsmodels  
- Jupyter Notebook

---

> _â€œModelos bem calibrados e interpretÃ¡veis sÃ£o tÃ£o importantes quanto modelos precisos.â€_
